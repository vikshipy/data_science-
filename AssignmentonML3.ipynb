{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0059d6c0-e059-4cb2-a04d-b319db636631",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some\n",
    "algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8011bd-3d63-4451-905e-c74e5a80380c",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Missing values in a dataset refer to the absence of data for certain observations or variables. It occurs when no data is recorded or available for a particular attribute in a dataset. Missing values can be represented in various ways, such as blank cells, \"NaN\" (Not a Number), \"NA\" (Not Available), or other placeholders.\n",
    "\n",
    "Handling missing values is crucial for several reasons:\n",
    "\n",
    "1. Reliable analysis: Missing values can lead to biased or inaccurate results if not properly handled. They can distort statistical measures, relationships between variables, and predictive models.\n",
    "\n",
    "2. Data completeness: Missing values hinder the analysis of the complete dataset and can limit the insights derived from it. By addressing missing values, you ensure the dataset is as complete as possible.\n",
    "\n",
    "3. Preserving data integrity: Missing values can introduce inconsistencies and errors when performing computations or applying algorithms that assume complete data. Handling missing values helps maintain the integrity of the dataset.\n",
    "\n",
    "Some algorithms that are not affected by missing values include:\n",
    "\n",
    "1. Decision Trees: Decision trees can handle missing values by considering alternative paths when missing values are encountered. Splitting criteria can be based on available values, allowing the algorithm to make decisions effectively.\n",
    "\n",
    "2. Random Forests: Similar to decision trees, random forests can handle missing values by leveraging the majority vote from multiple decision trees in the ensemble. Missing values are imputed at each tree's node based on available data.\n",
    "\n",
    "3. Gradient Boosting Machines (GBMs): GBMs, like XGBoost and LightGBM, can handle missing values by utilizing surrogate splits. The algorithm considers alternative variables to make splits when a missing value is encountered during tree construction.\n",
    "\n",
    "4. Gaussian Mixture Models (GMM): GMMs, an unsupervised learning algorithm, can handle missing values by utilizing the Expectation-Maximization (EM) algorithm. EM imputes missing values iteratively while estimating the parameters of the Gaussian distributions.\n",
    "\n",
    "It's important to note that while some algorithms can handle missing values internally, it's generally good practice to handle missing values appropriately before applying any algorithm to ensure accurate and reliable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75f438b-c41b-42c0-a635-a1d8c492706f",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Q2: List down techniques used to handle missing data.  Give an example of each with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55cd1c7-3d99-45e5-b20b-b1f3e618e91a",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "There are several techniques commonly used to handle missing data in a dataset. Here are four commonly employed techniques along with examples of how to implement them using Python:\n",
    "\n",
    "## 1-Deleting Rows or Columns:\n",
    "\n",
    "One straightforward approach is to remove rows or columns with missing values from the dataset. This technique is suitable when the missing values are relatively few compared to the overall dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a10db87-d422-4a68-9281-aeb37fd44e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B   C\n",
       "0  1.0  NaN  10\n",
       "1  2.0  6.0  11\n",
       "2  NaN  7.0  12\n",
       "3  4.0  NaN  13\n",
       "4  5.0  9.0  14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'A': [1, 2, None, 4, 5],\n",
    "        'B': [None, 6, 7, None, 9],\n",
    "        'C': [10, 11, 12, 13, 14]}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5b0292f-f0c4-41cf-9ac9-f05fe5b4b018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B   C\n",
       "1  2.0  6.0  11\n",
       "4  5.0  9.0  14"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dropping None values along with axis =0\n",
    "df_dropped = df.dropna(axis=0)\n",
    "df_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bccd786-3990-4d20-b910-6cfca540915b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C\n",
       "0  10\n",
       "1  11\n",
       "2  12\n",
       "3  13\n",
       "4  14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping columns with any missing values\n",
    "df_dropped_columns = df.dropna(axis=1)\n",
    "\n",
    "df_dropped_columns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675b728-f2ec-4c3d-8538-0526ce247990",
   "metadata": {},
   "source": [
    "## 2.Imputation Techniques:\n",
    "\n",
    "Imputation involves replacing missing values with estimated or calculated values based on the available data. Common methods include mean, median, mode, or regression imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60571c41-4a8a-4242-b414-c00aafb731a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B   C\n",
      "0  1.0  NaN  10\n",
      "1  2.0  6.0  11\n",
      "2  NaN  7.0  12\n",
      "3  4.0  NaN  13\n",
      "4  5.0  9.0  14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Creating a sample DataFrame with missing values\n",
    "data = {'A': [1, 2, None, 4, 5],\n",
    "        'B': [None, 6, 7, None, 9],\n",
    "        'C': [10, 11, 12, 13, 14]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "794e4b8f-5698-4f43-b92f-56c034d54c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A         B     C\n",
      "0  1.0  7.333333  10.0\n",
      "1  2.0  6.000000  11.0\n",
      "2  3.0  7.000000  12.0\n",
      "3  4.0  7.333333  13.0\n",
      "4  5.0  9.000000  14.0\n"
     ]
    }
   ],
   "source": [
    "# Imputing missing values with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "print(df_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857a9f58-37da-4062-9cbb-531c6b895316",
   "metadata": {},
   "source": [
    "## 3.Using Indicator Variables:\n",
    "\n",
    "This technique involves creating an additional binary column to indicate whether a value was missing or not. It allows the algorithm to capture potential patterns or relationships associated with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92949cc0-5ce2-4ef3-a1ed-7a6a2251fad2",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a sample DataFrame with missing values\n",
    "data = {'A': [1, 2, None, 4, 5],\n",
    "        'B': [None, 6, 7, None, 9],\n",
    "        'C': [10, 11, 12, 13, 14]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb17a421-320a-4529-89ab-daf4424461b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating indicator variables for missing values\n",
    "df_indicator = pd.DataFrame()\n",
    "for column in df.columns:\n",
    "    df_indicator[column + '_missing'] = np.where(df[column].isnull(), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1854bda3-0fee-460d-9a39-e64818f2fa4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_missing</th>\n",
       "      <th>B_missing</th>\n",
       "      <th>C_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A_missing  B_missing  C_missing\n",
       "0          0          1          0\n",
       "1          0          0          0\n",
       "2          1          0          0\n",
       "3          0          1          0\n",
       "4          0          0          0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indicator.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da119dc7-e8c9-4ce3-96da-ed63dde231a6",
   "metadata": {},
   "source": [
    "## 4.Advanced Techniques (e.g., Machine Learning-based):\n",
    "\n",
    "Advanced techniques involve using machine learning algorithms to predict missing values based on the available data. Methods such as K-Nearest Neighbors (KNN) imputation or regression models can be employed for this purpose.\n",
    "\n",
    "Example (KNN Imputation using the fancyimpute library):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2b75ba8-4aff-48fc-8f77-b50d0495d9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fancyimpute\n",
      "  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting knnimpute>=0.1.0\n",
      "  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (1.2.0)\n",
      "Collecting cvxpy\n",
      "  Downloading cvxpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cvxopt\n",
      "  Downloading cvxopt-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytest\n",
      "  Downloading pytest-7.3.1-py3-none-any.whl (320 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.5/320.5 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nose\n",
      "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.10 in /opt/conda/lib/python3.10/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.2.0)\n",
      "Collecting ecos>=2\n",
      "  Downloading ecos-2.0.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting osqp>=0.4.1\n",
      "  Downloading osqp-0.6.2.post9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.6/298.6 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting setuptools>65.5.1\n",
      "  Downloading setuptools-67.7.2-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scs>=1.1.6\n",
      "  Downloading scs-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (1.0.0)\n",
      "Collecting exceptiongroup>=1.0.0rc8\n",
      "  Downloading exceptiongroup-1.1.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (2.0.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (22.0)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting qdldl\n",
      "  Downloading qdldl-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: fancyimpute, knnimpute\n",
      "  Building wheel for fancyimpute (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29881 sha256=6e48bc658860e55e2adbae392c454819d59b8a7afb3d05e7d8dafe57cad15275\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/d4/dc/1d/df95900d5962d8a6da97306201c1695abe1922d56910ffa3b2\n",
      "  Building wheel for knnimpute (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11335 sha256=12ca4757fe2f0bb1bc9223951693258895cc8ed28df65c5fcf0eddd70b91186f\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/46/44/b7/0546c472093bdae2adaafdab7062ab6156f20c8e79af2ee999\n",
      "Successfully built fancyimpute knnimpute\n",
      "Installing collected packages: nose, setuptools, knnimpute, iniconfig, exceptiongroup, cvxopt, scs, qdldl, pytest, ecos, osqp, cvxpy, fancyimpute\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.5.1\n",
      "    Uninstalling setuptools-65.5.1:\n",
      "      Successfully uninstalled setuptools-65.5.1\n",
      "Successfully installed cvxopt-1.3.1 cvxpy-1.3.1 ecos-2.0.12 exceptiongroup-1.1.1 fancyimpute-0.7.0 iniconfig-2.0.0 knnimpute-0.1.0 nose-1.3.7 osqp-0.6.2.post9 pytest-7.3.1 qdldl-0.1.7 scs-3.2.3 setuptools-67.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install fancyimpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ee521e2-e581-475d-85a1-dcffcbe18031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/5 with 1 missing, elapsed time: 0.001\n",
      "          A         B     C\n",
      "0  1.000000  6.333333  10.0\n",
      "1  2.000000  6.000000  11.0\n",
      "2  2.777778  7.000000  12.0\n",
      "3  4.000000  7.777778  13.0\n",
      "4  5.000000  9.000000  14.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fancyimpute import KNN\n",
    "\n",
    "# Creating a sample DataFrame with missing values\n",
    "data = {'A': [1, 2, None, 4, 5],\n",
    "        'B': [None, 6, 7, None, 9],\n",
    "        'C': [10, 11, 12, 13, 14]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# KNN imputation\n",
    "imputer = KNN(k=3)\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "print(df_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f9adb-ff7f-4b32-b3aa-ccdb69db955b",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dcebd6-d2d4-44a6-96a2-bdabe6791c00",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Imbalanced data refers to a situation where the distribution of classes or categories in a dataset is highly disproportionate. In other words, one class or category has significantly more instances than the others, creating an imbalance. This issue commonly occurs in binary classification problems, where one class is the minority class (positive or rare class) and the other is the majority class (negative class).\n",
    "\n",
    "If imbalanced data is not handled appropriately, it can lead to several problems:\n",
    "\n",
    "1. Biased Model Performance: When a classification model is trained on imbalanced data, it tends to favor the majority class due to its higher representation in the dataset. As a result, the model's performance may be skewed, with low accuracy and poor predictive power for the minority class. The model may incorrectly classify most instances as the majority class, resulting in a high false negative rate for the minority class.\n",
    "\n",
    "2. Misleading Evaluation Metrics: Evaluation metrics such as accuracy can be misleading when dealing with imbalanced data. Even if a model achieves high accuracy, it may not reflect its performance on the minority class, which is often of greater interest. Metrics such as precision, recall, F1 score, and area under the ROC curve (AUC-ROC) provide a better understanding of the model's performance in imbalanced scenarios.\n",
    "\n",
    "3. Reduced Generalization: Imbalanced data can negatively impact a model's ability to generalize to unseen data, especially for the minority class. The model may become overly specialized in predicting the majority class and may fail to perform well on new, balanced data. This limits the model's real-world applicability.\n",
    "\n",
    "4. Decision-Making Bias: In real-world scenarios, biased decisions based on imbalanced data can have serious consequences. For example, in fraud detection, a model trained on imbalanced data may have a high false negative rate, leading to many undetected fraudulent transactions.\n",
    "\n",
    "To address the issues arising from imbalanced data, various techniques can be employed, such as:\n",
    "\n",
    "- Resampling techniques: Oversampling the minority class (e.g., SMOTE) or undersampling the majority class can balance the class distribution.\n",
    "- Generating synthetic samples: Techniques like Synthetic Minority Over-sampling Technique (SMOTE) can generate synthetic instances of the minority class to balance the data.\n",
    "- Algorithmic techniques: Algorithms designed specifically for imbalanced data, such as Cost-Sensitive Learning, ensemble methods (e.g., Random Forest, Gradient Boosting), or anomaly detection algorithms, can be used.\n",
    "\n",
    "By applying these techniques, the impact of imbalanced data can be mitigated, leading to improved model performance, fair evaluation metrics, better generalization, and more reliable decision-making in real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444cd772-c14b-4a97-8b5e-acc61627f20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b3276cb-a696-48b4-8fd2-d03a5eda7a13",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Upsampling and downsampling are resampling techniques used to address class imbalance in a dataset. Here's an explanation of each technique along with examples of when they are required:\n",
    "\n",
    "1. Upsampling (Over-sampling):\n",
    "   Upsampling involves increasing the number of instances in the minority class to match the number of instances in the majority class. This technique aims to balance the class distribution by replicating or generating synthetic samples of the minority class.\n",
    "\n",
    "   Example:\n",
    "   Suppose you have a dataset for fraud detection with 1,000 instances, of which only 50 are fraud cases (minority class) and the rest are non-fraud cases (majority class). To upsample the minority class, you can replicate or generate synthetic instances of the fraud cases to match the number of non-fraud cases. This helps create a balanced dataset that can be used to train a classification model.\n",
    "\n",
    "   Upsampling is typically applied when the available data for the minority class is limited, and replicating or generating synthetic instances can help improve the model's ability to learn from the minority class.\n",
    "\n",
    "2. Downsampling (Under-sampling):\n",
    "   Downsampling involves reducing the number of instances in the majority class to match the number of instances in the minority class. This technique aims to balance the class distribution by randomly selecting a subset of instances from the majority class.\n",
    "\n",
    "   Example:\n",
    "   Continuing with the fraud detection example, if you have 1,000 instances, out of which 950 are non-fraud cases (majority class) and 50 are fraud cases (minority class), you can downsample the majority class by randomly selecting 50 instances. This creates a balanced dataset where both classes are equally represented.\n",
    "\n",
    "   Downsampling is typically applied when the majority class instances significantly outnumber the minority class instances, and reducing the majority class instances can help alleviate the class imbalance.\n",
    "\n",
    "The choice between upsampling and downsampling depends on the specific characteristics of the dataset and the available data. Upsampling is useful when the minority class is underrepresented and generating synthetic instances or replicating existing ones can help improve the model's performance. Downsampling is suitable when the majority class instances dominate the dataset, and reducing their number can help balance the classes.\n",
    "\n",
    "It's important to note that both upsampling and downsampling techniques should be applied with caution. Upsampling can lead to overfitting or synthetic data that may not accurately represent the minority class, while downsampling can discard potentially useful information from the majority class. Evaluating the impact of these techniques on the model's performance and considering other approaches like algorithmic adjustments or ensemble methods is advisable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb65782c-104d-452f-b40a-76eec33cab2e",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a80af-a137-4985-8a59-d7bd069ce239",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Data augmentation is a technique used to artificially increase the size of a dataset by creating modified or synthetic samples based on the existing data. It is commonly used in machine learning and deep learning tasks, particularly when the available dataset is limited or imbalanced. Data augmentation helps improve model performance by introducing additional variation, reducing overfitting, and increasing the model's ability to generalize.\n",
    "\n",
    "One popular data augmentation technique is Synthetic Minority Over-sampling Technique (SMOTE). SMOTE addresses the class imbalance problem by generating synthetic samples for the minority class based on the existing minority class instances.\n",
    "\n",
    "Here's how SMOTE works:\n",
    "\n",
    "1. Identify the minority class instances that need augmentation.\n",
    "\n",
    "2. For each minority class instance, find its k nearest neighbors in the feature space (typically using Euclidean distance).\n",
    "\n",
    "3. Randomly select one of the k nearest neighbors, and compute the difference between the feature values of the selected instance and the current minority instance.\n",
    "\n",
    "4. Multiply this difference by a random number between 0 and 1 to obtain a new synthetic sample.\n",
    "\n",
    "5. Repeat this process for each minority class instance, generating the desired number of synthetic samples.\n",
    "\n",
    "The synthetic samples generated by SMOTE are new instances that lie along the line segments connecting the minority class instances and their selected nearest neighbors. This process effectively expands the feature space and introduces additional variations, thereby addressing the class imbalance problem.\n",
    "\n",
    "For example, suppose you have a dataset with two classes: Class A (majority class) and Class B (minority class). Class B has fewer instances. Applying SMOTE will create synthetic samples for Class B by considering the k nearest neighbors of each Class B instance. The synthetic samples will be placed along the line segments connecting the instances.\n",
    "\n",
    "SMOTE helps balance the class distribution, improves the model's ability to learn from the minority class, and reduces the bias towards the majority class.\n",
    "\n",
    "It's worth noting that SMOTE assumes that the minority class instances are close enough in feature space to be connected by line segments. If the feature space is complex or there are distinct clusters within the minority class, additional techniques or modifications may be required.\n",
    "\n",
    "SMOTE is implemented in various machine learning libraries, such as imbalanced-learn in Python. By applying SMOTE, you can effectively augment the minority class and create a more balanced dataset for training classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3a9671-82b4-4fdd-b2cd-135d7a834d0f",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be48c5bb-da03-4948-89f7-e88f08b0c4b1",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Outliers are observations in a dataset that significantly deviate from the majority of the other observations. They are data points that lie at an abnormal distance from the central tendency or follow a different pattern compared to the rest of the data. Outliers can occur due to various reasons, such as measurement errors, data entry mistakes, or genuinely extreme values in the underlying phenomenon being measured.\n",
    "\n",
    "It is essential to handle outliers for several reasons:\n",
    "\n",
    "1. Data Integrity: Outliers can indicate potential errors or inconsistencies in the data collection process. Identifying and handling outliers helps maintain the integrity and quality of the dataset.\n",
    "\n",
    "2. Distortion of Statistical Measures: Outliers can significantly impact statistical measures such as the mean and standard deviation, which are sensitive to extreme values. These measures may not accurately represent the central tendency and spread of the data when outliers are present.\n",
    "\n",
    "3. Skewed Analysis and Interpretation: Outliers can skew the analysis and interpretation of the data. They can lead to incorrect conclusions, misinterpretations of relationships between variables, and biased predictive models.\n",
    "\n",
    "4. Impact on Model Performance: Outliers can disproportionately influence the fitting of models, particularly those sensitive to extreme values. They can lead to overfitting, where the model is excessively tailored to the outliers, or underfitting, where the model fails to capture the overall patterns in the data.\n",
    "\n",
    "5. Violation of Assumptions: Some statistical and machine learning algorithms assume that the data follows certain distributional assumptions, such as normality. Outliers can violate these assumptions, affecting the validity of the analysis and the accuracy of the models.\n",
    "\n",
    "Handling outliers can be approached in different ways, depending on the specific context and requirements of the analysis. Some common techniques include:\n",
    "\n",
    "- Removal: Outliers can be removed from the dataset if they are identified as erroneous or irrelevant to the analysis. However, caution should be exercised when removing outliers, as they may contain valuable information or represent genuine extreme values.\n",
    "\n",
    "- Transformation: Data transformation techniques such as logarithmic transformation or winsorization can be applied to reduce the impact of outliers while preserving the overall distribution and relationships.\n",
    "\n",
    "- Robust Statistics: Robust statistical measures, such as the median and interquartile range, are less sensitive to outliers compared to mean and standard deviation. Using robust statistics can provide more robust estimations and analysis results.\n",
    "\n",
    "- Model-specific Approaches: Some algorithms and models have built-in mechanisms to handle outliers. For instance, robust regression methods, such as RANSAC or Huber regression, are designed to be less affected by outliers in the data.\n",
    "\n",
    "By appropriately handling outliers, analysts and data scientists can ensure accurate and reliable analyses, improve model performance, and enhance the understanding and interpretation of the underlying data patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e4a26e-15ba-469f-9c7b-a69ad8ba7e3c",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of\n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3b241-6bd5-4047-88a5-654d2f769a04",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "When dealing with missing data in customer data analysis, there are several techniques that can be used to handle the missing values. Here are a few commonly employed techniques:\n",
    "\n",
    "1. Deletion: In this technique, you remove the rows or columns with missing values from the dataset. This approach can be used if the missing data is minimal, and removing them does not significantly impact the analysis.\n",
    "\n",
    "2. Imputation: Imputation involves filling in the missing values with estimated or calculated values based on the available data. Various imputation methods can be employed, such as mean imputation (replacing missing values with the mean of the available values), median imputation, mode imputation, or regression imputation (using regression models to predict missing values based on other variables).\n",
    "\n",
    "3. Hot Deck Imputation: Hot deck imputation is a method where missing values are imputed by borrowing values from similar or \"nearest neighbors\" in the dataset. The nearest neighbors can be identified based on various criteria, such as similar attributes or clustering techniques.\n",
    "\n",
    "4. Multiple Imputation: Multiple imputation involves generating multiple imputations for missing values using statistical models. Multiple imputations provide a range of plausible values for each missing observation, considering the uncertainty associated with imputing missing data.\n",
    "\n",
    "5. Machine Learning-based Imputation: Machine learning algorithms can be employed to predict missing values based on the available data. Techniques such as K-Nearest Neighbors (KNN) imputation or regression models can be used for this purpose.\n",
    "\n",
    "6. Indicator Variables: Indicator variables, also known as dummy variables, can be created to indicate whether a value is missing or not. These variables can capture any potential patterns or relationships associated with missing values and include them as a feature in the analysis.\n",
    "\n",
    "The choice of technique depends on factors such as the extent of missing data, the nature of the variables, the relationship between variables, and the goals of the analysis. It is important to carefully consider the potential impact of each technique on the data and the analysis results, and to select the most appropriate approach accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3379ce3d-33c6-493e-b2b6-faa689008af8",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673fb5c2-dcd0-4d40-a484-23fa35d83074",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "When dealing with missing data in a large dataset, it is crucial to determine if the missingness is random or if there is a pattern or mechanism behind it. Understanding the nature of missingness can help in selecting appropriate strategies to handle missing data and minimize potential biases. Here are some strategies to determine if the missing data is missing at random or if there is a pattern:\n",
    "\n",
    "1. Missing Data Visualization: Visualizing the missing data pattern can provide initial insights into the presence of any patterns. You can create visualizations such as heatmaps or bar plots to display the missingness of variables or use missing data matrices to visualize the missingness patterns across the dataset.\n",
    "\n",
    "2. Missingness Summary: Calculating summary statistics can help identify any systematic differences between missing and non-missing values. You can compute summary statistics (e.g., mean, median, mode) separately for the missing and non-missing groups and compare them. If the summary statistics significantly differ between the two groups, it suggests a potential pattern in the missing data.\n",
    "\n",
    "3. Missingness Tests: Statistical tests can be conducted to assess the relationship between missingness and other variables. For example, a chi-square test or Fisher's exact test can be used to examine the association between missingness and categorical variables. Similarly, t-tests or ANOVA can be employed to analyze the relationship between missingness and continuous variables.\n",
    "\n",
    "4. Missing Data Mechanism: Various missing data mechanisms can provide insights into the nature of missingness. For example:\n",
    "   - Missing Completely at Random (MCAR): The missingness occurs randomly and is unrelated to the observed or unobserved data.\n",
    "   - Missing at Random (MAR): The missingness is related to the observed data but not to the unobserved data.\n",
    "   - Missing Not at Random (MNAR): The missingness is related to the unobserved data or variables that are missing.\n",
    "\n",
    "   Understanding the underlying mechanism can guide the selection of appropriate missing data handling techniques.\n",
    "\n",
    "5. Multiple Imputation: Multiple imputation can be used to estimate missing values by creating multiple plausible imputations. By comparing the imputed values with the observed values, you can examine if there is any systematic pattern in the imputed values that differs from the observed values.\n",
    "\n",
    "6. Domain Knowledge and Expertise: Incorporating domain knowledge and subject matter expertise is crucial in determining patterns in missing data. Experts familiar with the data and the context may provide insights into potential reasons for missingness or patterns in the missing data.\n",
    "\n",
    "By applying these strategies, you can gain a better understanding of the missing data patterns and determine if the missingness is random or if there are specific patterns or mechanisms behind it. This knowledge helps in making informed decisions on how to handle the missing data and mitigate potential biases in subsequent analysis or modeling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb964c1-f630-42a8-a513-3b190b5896b0",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the\n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613b918e-4291-47c0-aa86-f50813fe40db",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "When working with imbalanced datasets, where the majority class significantly outweighs the minority class, evaluating the performance of machine learning models can be challenging. Traditional evaluation metrics may be misleading due to the inherent bias towards the majority class. Here are some strategies to evaluate the performance of your machine learning model on an imbalanced dataset:\n",
    "\n",
    "1. Confusion Matrix: Start by analyzing the confusion matrix, which provides a detailed breakdown of the model's predictions. It includes true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). This matrix can help evaluate the model's performance and identify any imbalances in class predictions.\n",
    "\n",
    "2. Accuracy Paradox: Be cautious when relying solely on accuracy as an evaluation metric. Accuracy alone can be misleading in imbalanced datasets since a model that predicts only the majority class can still achieve high accuracy. Therefore, it's crucial to consider additional metrics.\n",
    "\n",
    "3. Precision and Recall: Precision and recall are important metrics in imbalanced datasets. Precision measures the proportion of correctly predicted positive instances out of the total predicted positive instances (TP / (TP + FP)), while recall measures the proportion of correctly predicted positive instances out of the total actual positive instances (TP / (TP + FN)). These metrics provide insights into the model's ability to correctly identify the minority class.\n",
    "\n",
    "4. F1 Score: The F1 score is the harmonic mean of precision and recall, combining both metrics into a single value. It provides a balanced measure of the model's performance, considering both the precision and recall values. F1 score can be a useful metric when the aim is to find a balance between precision and recall.\n",
    "\n",
    "5. Receiver Operating Characteristic (ROC) Curve: The ROC curve is a graphical representation that illustrates the trade-off between true positive rate (TPR) and false positive rate (FPR) at various classification thresholds. AUC-ROC (Area Under the ROC Curve) is a commonly used metric to evaluate the overall performance of a model on imbalanced datasets. A higher AUC-ROC indicates better discriminatory power of the model.\n",
    "\n",
    "6. Precision-Recall Curve: The precision-recall curve is another graphical representation that shows the trade-off between precision and recall at different classification thresholds. It provides a more insightful evaluation for imbalanced datasets, particularly when the focus is on the minority class. A higher area under the precision-recall curve indicates better performance.\n",
    "\n",
    "7. Resampling Techniques: Resampling techniques such as upsampling the minority class or downsampling the majority class can be used to balance the dataset before model training. This can help improve the model's performance and reduce the bias towards the majority class.\n",
    "\n",
    "8. Cost-Sensitive Learning: Assigning different misclassification costs to different classes can be beneficial. By assigning a higher misclassification cost to the minority class, the model is encouraged to pay more attention to correctly predicting the minority class.\n",
    "\n",
    "9. Ensemble Methods: Ensemble methods, such as bagging, boosting, or stacking, can be effective in handling imbalanced datasets. These methods combine multiple models to create a more robust and accurate prediction.\n",
    "\n",
    "When evaluating the performance of machine learning models on imbalanced datasets, it is crucial to consider a combination of metrics and techniques that focus on the performance of the minority class. This ensures a comprehensive assessment of the model's ability to correctly identify the positive instances and avoids overly optimistic evaluations due to the majority class bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e282265-8da5-41d1-959f-06d1cce7f7e9",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe2e97-035d-49eb-a522-b0507fe1d92e",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "To balance an unbalanced dataset with the majority class being satisfied customers, you can employ down-sampling techniques to reduce the number of samples in the majority class. Down-sampling involves randomly removing samples from the majority class to match the number of samples in the minority class. Here's a step-by-step guide on how to perform down-sampling:\n",
    "\n",
    "1. Identify the majority and minority classes: In this case, the majority class is the satisfied customers, and the minority class is the unsatisfied customers.\n",
    "\n",
    "2. Determine the desired balance ratio: Decide on the desired ratio between the majority and minority classes after down-sampling. For instance, you may aim for a 1:1 ratio or any other ratio that suits your analysis goals.\n",
    "\n",
    "3. Randomly select samples from the majority class: Randomly select a subset of samples from the majority class to match the number of samples in the minority class. You can use various random sampling techniques, such as random sampling without replacement, to ensure each selected sample is unique.\n",
    "\n",
    "4. Create the balanced dataset: Combine the randomly selected samples from the majority class with the original samples from the minority class to create a new balanced dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd396cb-5fe3-49b6-8f72-18e720dcbc75",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a\n",
    "project that requires you to estimate the occurrence of a rare event. What methods can you employ to\n",
    "balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef5dede-0dc3-4f36-af81-c8737e26e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "\n",
    "To balance an unbalanced dataset with a low percentage of occurrences of a rare event, you can employ up-sampling techniques to increase the number of samples in the minority class. Up-sampling involves replicating or generating new samples in the minority class to match the number of samples in the majority class. Here's a step-by-step guide on how to perform up-sampling:\n",
    "\n",
    "1. Identify the majority and minority classes: In this case, the minority class is the rare event, and the majority class is the non-occurrences.\n",
    "\n",
    "2. Determine the desired balance ratio: Decide on the desired ratio between the minority and majority classes after up-sampling. For instance, you may aim for a 1:1 ratio or any other ratio that suits your analysis goals.\n",
    "\n",
    "3. Up-sample the minority class: There are several techniques to up-sample the minority class:\n",
    "   - Random Up-sampling: Randomly select samples from the minority class and duplicate them to match the number of samples in the majority class. This can be done with or without replacement.\n",
    "   - Synthetic Minority Over-sampling Technique (SMOTE): SMOTE generates synthetic samples by interpolating between existing minority class samples. It creates new samples along the line segments connecting the minority class samples to their nearest neighbors. SMOTE helps address the risk of overfitting when duplicating existing samples.\n",
    "   - ADASYN (Adaptive Synthetic Sampling): ADASYN is an extension of SMOTE that focuses on generating more synthetic samples for difficult-to-learn minority samples. It introduces a density-based approach to determine the number of synthetic samples to generate for each minority sample.\n",
    "\n",
    "4. Create the balanced dataset: Combine the up-sampled minority class samples with the original majority class samples to create a new balanced dataset.\n",
    "\n",
    "Here's an example Python code snippet demonstrating how to up-sample the minority class using the scikit-learn library and SMOTE:\n",
    "\n",
    "```python\n",
    "from imble"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
